{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import spacy\n",
    "from spacy.matcher import Matcher, PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdvancedSchemaToGraphConverter:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.Graph()\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.matcher = Matcher(self.nlp.vocab)\n",
    "        self.phrase_matcher = PhraseMatcher(self.nlp.vocab)\n",
    "        \n",
    "        # Define patterns for common SQL operations\n",
    "        self.matcher.add(\"AGGREGATION\", [[{\"LOWER\": {\"IN\": [\"average\", \"avg\", \"sum\", \"count\", \"max\", \"min\"]}}]])\n",
    "        self.matcher.add(\"GROUPING\", [[{\"LOWER\": \"group\"}, {\"LOWER\": \"by\"}]])\n",
    "        self.matcher.add(\"ORDERING\", [[{\"LOWER\": {\"IN\": [\"order\", \"sort\"]}}, {\"LOWER\": \"by\"}]])\n",
    "        self.matcher.add(\"LIMIT\", [[{\"LOWER\": {\"IN\": [\"top\", \"bottom\"]}}, {\"POS\": \"NUM\"}]])\n",
    "        self.matcher.add(\"TIME_RANGE\", [[{\"LOWER\": {\"IN\": [\"last\", \"past\"]}}, {\"POS\": \"NUM\"}, {\"LOWER\": {\"IN\": [\"day\", \"week\", \"month\", \"year\"]}}]])\n",
    "\n",
    "        # Add patterns for specific business concepts\n",
    "        self.matcher.add(\"CUSTOMER_RETENTION\", [[{\"LOWER\": \"customer\"}, {\"LOWER\": \"retention\"}]])\n",
    "        self.matcher.add(\"POPULAR_PRODUCTS\", [[{\"LOWER\": \"popular\"}, {\"LOWER\": \"products\"}]])\n",
    "        self.matcher.add(\"BOUGHT_TOGETHER\", [[{\"LOWER\": \"bought\"}, {\"LOWER\": \"together\"}]])\n",
    "\n",
    "    def load_schema(self, schema_json: str):\n",
    "        schema = json.loads(schema_json)\n",
    "        self._process_schema(schema)\n",
    "        self._update_phrase_matcher()\n",
    "\n",
    "    def _process_schema(self, schema: Dict[str, Any]):\n",
    "        for table_name, table_info in schema.items():\n",
    "            self._add_table_node(table_name, table_info)\n",
    "            self._process_columns(table_name, table_info['columns'])\n",
    "            self._process_relationships(table_name, table_info.get('relationships', []))\n",
    "\n",
    "    def _add_table_node(self, table_name: str, table_info: Dict[str, Any]):\n",
    "        self.graph.add_node(table_name, type='table', description=table_info.get('description', ''))\n",
    "\n",
    "    def _process_columns(self, table_name: str, columns: Dict[str, Any]):\n",
    "        for column_name, column_info in columns.items():\n",
    "            column_node = f\"{table_name}.{column_name}\"\n",
    "            self.graph.add_node(column_node, type='column', \n",
    "                                data_type=column_info['data_type'],\n",
    "                                constraints=column_info.get('constraints', []))\n",
    "            self.graph.add_edge(table_name, column_node, type='has_column')\n",
    "\n",
    "    def _process_relationships(self, table_name: str, relationships: list):\n",
    "        for relationship in relationships:\n",
    "            related_table = relationship['related_table']\n",
    "            self.graph.add_edge(table_name, related_table, type='related_to',\n",
    "                                relationship_type=relationship['type'])\n",
    "\n",
    "    def _update_phrase_matcher(self):\n",
    "        patterns = []\n",
    "        for node in self.graph.nodes():\n",
    "            if self.graph.nodes[node]['type'] in ['table', 'column']:\n",
    "                patterns.append(self.nlp(node.lower()))\n",
    "        self.phrase_matcher.add(\"SCHEMA_ELEMENTS\", patterns)\n",
    "\n",
    "    def advanced_question_processing(self, question: str) -> Dict[str, Any]:\n",
    "        doc = self.nlp(question.lower())\n",
    "        \n",
    "        # Extract entities and operations\n",
    "        entities = [ent.text for ent in doc.ents]\n",
    "        operations = []\n",
    "        for match_id, start, end in self.matcher(doc):\n",
    "            operations.append(doc[start:end].text)\n",
    "        \n",
    "        # Get relevant tables and columns\n",
    "        matches = self.phrase_matcher(doc)\n",
    "        relevant_elements = [doc[start:end].text for _, start, end in matches]\n",
    "        \n",
    "        tables, columns = self._classify_relevant_elements(relevant_elements)\n",
    "        \n",
    "        # Expand tables and columns based on the question context\n",
    "        expanded_tables, expanded_columns = self._expand_relevant_elements(tables, columns, doc)\n",
    "        \n",
    "        # Identify potential joins and related tables\n",
    "        potential_joins = self.find_potential_joins(expanded_tables)\n",
    "        \n",
    "        return {\n",
    "            \"entities\": entities,\n",
    "            \"operations\": operations,\n",
    "            \"tables\": expanded_tables,\n",
    "            \"columns\": expanded_columns,\n",
    "            \"potential_joins\": potential_joins\n",
    "        }\n",
    "\n",
    "    def _classify_relevant_elements(self, elements: List[str]) -> Tuple[List[str], List[str]]:\n",
    "        tables = []\n",
    "        columns = []\n",
    "        for element in elements:\n",
    "            if '.' in element:\n",
    "                columns.append(element)\n",
    "            else:\n",
    "                tables.append(element)\n",
    "        return tables, columns\n",
    "\n",
    "    def _expand_relevant_elements(self, tables: List[str], columns: List[str], doc) -> Tuple[List[str], List[str]]:\n",
    "        expanded_tables = set(tables)\n",
    "        expanded_columns = set(columns)\n",
    "        \n",
    "        # Expand based on relationships\n",
    "        for table in tables:\n",
    "            expanded_tables.update(self.get_related_tables(table))\n",
    "        \n",
    "        # Expand based on common query patterns\n",
    "        if any(token.text in ['total', 'sum', 'amount'] for token in doc):\n",
    "            expanded_columns.add('orders.total_amount')\n",
    "            expanded_tables.add('orders')\n",
    "        \n",
    "        if any(token.text in ['customer', 'user'] for token in doc):\n",
    "            expanded_tables.add('users')\n",
    "        \n",
    "        if any(token.text in ['product', 'item'] for token in doc):\n",
    "            expanded_tables.add('products')\n",
    "            expanded_tables.add('order_items')\n",
    "        \n",
    "        if any(token.text in ['category'] for token in doc):\n",
    "            expanded_columns.add('products.category')\n",
    "        \n",
    "        if any(token.text in ['bought', 'purchased', 'together'] for token in doc):\n",
    "            expanded_tables.update(['orders', 'order_items', 'products'])\n",
    "        \n",
    "        # Expand columns for all tables\n",
    "        for table in expanded_tables:\n",
    "            expanded_columns.update(self.get_table_columns(table))\n",
    "        \n",
    "        return list(expanded_tables), list(expanded_columns)\n",
    "\n",
    "    def get_related_tables(self, table: str) -> List[str]:\n",
    "        if table not in self.graph:\n",
    "            return []\n",
    "        return [node for node in nx.neighbors(self.graph, table) \n",
    "                if self.graph.nodes[node]['type'] == 'table']\n",
    "\n",
    "    def get_table_columns(self, table: str) -> List[str]:\n",
    "        if table not in self.graph:\n",
    "            return []\n",
    "        return [node for node in nx.neighbors(self.graph, table) \n",
    "                if self.graph.nodes[node]['type'] == 'column']\n",
    "\n",
    "    def find_potential_joins(self, tables: List[str]) -> List[tuple]:\n",
    "        joins = []\n",
    "        for i in range(len(tables)):\n",
    "            for j in range(i+1, len(tables)):\n",
    "                if tables[i] in self.graph and tables[j] in self.graph:\n",
    "                    try:\n",
    "                        path = nx.shortest_path(self.graph, tables[i], tables[j])\n",
    "                        joins.append((tables[i], tables[j], path))\n",
    "                    except nx.NetworkXNoPath:\n",
    "                        continue\n",
    "        return joins\n",
    "\n",
    "    def visualize(self):\n",
    "        pos = nx.spring_layout(self.graph, k=0.5, iterations=50)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        color_map = {\n",
    "            'table': '#FF9999',\n",
    "            'column': '#66B2FF',\n",
    "        }\n",
    "        \n",
    "        for node_type in color_map:\n",
    "            node_list = [node for node, data in self.graph.nodes(data=True) if data['type'] == node_type]\n",
    "            nx.draw_networkx_nodes(self.graph, pos, nodelist=node_list, node_color=color_map[node_type], node_size=3000, alpha=0.8)\n",
    "\n",
    "        nx.draw_networkx_edges(self.graph, pos, alpha=0.5)\n",
    "        \n",
    "        labels = {node: node for node in self.graph.nodes()}\n",
    "        nx.draw_networkx_labels(self.graph, pos, labels, font_size=8)\n",
    "        \n",
    "        legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=node_type.capitalize(),\n",
    "                          markerfacecolor=color, markersize=10)\n",
    "                          for node_type, color in color_map.items()]\n",
    "        plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "        plt.title(\"Database Schema Graph Visualization\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "converter = AdvancedSchemaToGraphConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load schema (using the extended schema from before)\n",
    "schema_json = '''\n",
    "{\n",
    "    \"users\": {\n",
    "        \"description\": \"Store user information\",\n",
    "        \"columns\": {\n",
    "            \"id\": {\"data_type\": \"integer\", \"constraints\": [\"primary_key\"]},\n",
    "            \"username\": {\"data_type\": \"varchar\", \"constraints\": [\"unique\"]},\n",
    "            \"email\": {\"data_type\": \"varchar\", \"constraints\": [\"unique\"]},\n",
    "            \"age\": {\"data_type\": \"integer\"},\n",
    "            \"registration_date\": {\"data_type\": \"date\"}\n",
    "        },\n",
    "        \"relationships\": [\n",
    "            {\"related_table\": \"orders\", \"type\": \"has_many\"}\n",
    "        ]\n",
    "    },\n",
    "    \"orders\": {\n",
    "        \"description\": \"Store order information\",\n",
    "        \"columns\": {\n",
    "            \"id\": {\"data_type\": \"integer\", \"constraints\": [\"primary_key\"]},\n",
    "            \"user_id\": {\"data_type\": \"integer\", \"constraints\": [\"foreign_key\"]},\n",
    "            \"total_amount\": {\"data_type\": \"decimal\"},\n",
    "            \"date\": {\"data_type\": \"date\"}\n",
    "        },\n",
    "        \"relationships\": [\n",
    "            {\"related_table\": \"users\", \"type\": \"belongs_to\"},\n",
    "            {\"related_table\": \"order_items\", \"type\": \"has_many\"}\n",
    "        ]\n",
    "    },\n",
    "    \"products\": {\n",
    "        \"description\": \"Store product information\",\n",
    "        \"columns\": {\n",
    "            \"id\": {\"data_type\": \"integer\", \"constraints\": [\"primary_key\"]},\n",
    "            \"name\": {\"data_type\": \"varchar\"},\n",
    "            \"price\": {\"data_type\": \"decimal\"},\n",
    "            \"category\": {\"data_type\": \"varchar\"}\n",
    "        },\n",
    "        \"relationships\": [\n",
    "            {\"related_table\": \"order_items\", \"type\": \"has_many\"}\n",
    "        ]\n",
    "    },\n",
    "    \"order_items\": {\n",
    "        \"description\": \"Store items within each order\",\n",
    "        \"columns\": {\n",
    "            \"id\": {\"data_type\": \"integer\", \"constraints\": [\"primary_key\"]},\n",
    "            \"order_id\": {\"data_type\": \"integer\", \"constraints\": [\"foreign_key\"]},\n",
    "            \"product_id\": {\"data_type\": \"integer\", \"constraints\": [\"foreign_key\"]},\n",
    "            \"quantity\": {\"data_type\": \"integer\"}\n",
    "        },\n",
    "        \"relationships\": [\n",
    "            {\"related_table\": \"orders\", \"type\": \"belongs_to\"},\n",
    "            {\"related_table\": \"products\", \"type\": \"belongs_to\"}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the advanced question processing with the problematic questions\n",
    "questions = [\n",
    "    # \"Who are the top 5 customers by total spending in the last month?\",\n",
    "    # \"What is the most popular product category among customers aged 25-35?\",\n",
    "    \"Who are the top 3 customers in each product category by total spending?\",\n",
    "    # \"What is the month-over-month growth rate in total sales for each product category?\",\n",
    "    # \"Which products are often bought together?\",\n",
    "    # \"Which customers have purchased all products in a specific category?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Who are the top 3 customers in each product category by total spending?\n",
      "Advanced processing result:\n",
      "{\n",
      "  \"entities\": [\n",
      "    \"3\"\n",
      "  ],\n",
      "  \"operations\": [\n",
      "    \"top 3\"\n",
      "  ],\n",
      "  \"tables\": [\n",
      "    \"products\",\n",
      "    \"orders\",\n",
      "    \"order_items\"\n",
      "  ],\n",
      "  \"columns\": [\n",
      "    \"products.category\",\n",
      "    \"orders.total_amount\"\n",
      "  ],\n",
      "  \"potential_joins\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    result = converter.advanced_question_processing(question)\n",
    "    print(\"Advanced processing result:\")\n",
    "    print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
